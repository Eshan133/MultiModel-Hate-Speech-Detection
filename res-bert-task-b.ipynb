{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a88147f",
   "metadata": {
    "papermill": {
     "duration": 0.005944,
     "end_time": "2025-07-12T03:57:29.472599",
     "exception": false,
     "start_time": "2025-07-12T03:57:29.466655",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Resnet and Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05ad0d64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:57:29.484662Z",
     "iopub.status.busy": "2025-07-12T03:57:29.484228Z",
     "iopub.status.idle": "2025-07-12T03:58:04.961506Z",
     "shell.execute_reply": "2025-07-12T03:58:04.960711Z"
    },
    "papermill": {
     "duration": 35.484728,
     "end_time": "2025-07-12T03:58:04.963097",
     "exception": false,
     "start_time": "2025-07-12T03:57:29.478369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 03:57:50.836447: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752292671.056544      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752292671.120100      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# 1. Required Imports\n",
    "import os, re, json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from transformers import BertTokenizer, BertModel, get_cosine_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26da4ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:58:04.974359Z",
     "iopub.status.busy": "2025-07-12T03:58:04.973797Z",
     "iopub.status.idle": "2025-07-12T03:58:04.979442Z",
     "shell.execute_reply": "2025-07-12T03:58:04.978238Z"
    },
    "papermill": {
     "duration": 0.012999,
     "end_time": "2025-07-12T03:58:04.981152",
     "exception": false,
     "start_time": "2025-07-12T03:58:04.968153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "print([f for f in os.listdir() if 'torchvision' in f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "735e92c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:58:04.992145Z",
     "iopub.status.busy": "2025-07-12T03:58:04.991876Z",
     "iopub.status.idle": "2025-07-12T03:58:05.182697Z",
     "shell.execute_reply": "2025-07-12T03:58:05.181436Z"
    },
    "papermill": {
     "duration": 0.197895,
     "end_time": "2025-07-12T03:58:05.184127",
     "exception": true,
     "start_time": "2025-07-12T03:58:04.986232",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/subtask3-comp2025-multimodel/train/Subtask C Train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/1909688018.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mrecords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/Subtask C Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlabel_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/Subtask C Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/subtask3-comp2025-multimodel/train/Subtask C Train'"
     ]
    }
   ],
   "source": [
    "# 2. Label Mapping\n",
    "LABEL_MAP = {'Neutral': 0, 'Support': 1, 'Oppose': 2}\n",
    "INVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "root = \"/kaggle/input/subtask3-comp2025-multimodel/\"\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 3. Clean text function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|@\\w+|#\\w+|[^\\w\\s]\", \"\", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "# 4. Load DataFrames\n",
    "def getIndexAndPath(folder):\n",
    "    paths = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith((\".png\")):\n",
    "            paths.append({\n",
    "                \"index\": filename,\n",
    "                \"image_path\": os.path.join(folder, filename)\n",
    "            })\n",
    "    return paths\n",
    "\n",
    "records = []\n",
    "# Train DF\n",
    "records = []\n",
    "for label_name in os.listdir(os.path.join(root, \"train/Subtask C Train\")):\n",
    "    label_folder = os.path.join(os.path.join(root, \"train/Subtask C Train\"), label_name)\n",
    "    if not os.path.isdir(label_folder): continue\n",
    "    label_id = LABEL_MAP[label_name]\n",
    "    records += getIndexAndPath(label_folder)\n",
    "df_images = pd.DataFrame(records)\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"train/STask_C_train.csv\"))\n",
    "df_train = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "# Test DF\n",
    "df_images = pd.DataFrame(getIndexAndPath(os.path.join(root, \"test/STask_C_test_img\")))\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"test/STask-C(index,text)test.csv\"))\n",
    "df_test = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "# Eval DF\n",
    "df_images = pd.DataFrame(getIndexAndPath(os.path.join(root, \"eval/STask_C_val_img\")))\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"eval/STask-C(index,text)val.csv\"))\n",
    "df_labels = pd.read_csv(os.path.join(root, \"eval/STask-C(index,label)val.csv\"))\n",
    "df_eval = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "df_val = pd.merge(df_eval, df_labels, on=\"index\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba2cf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:47.807884Z",
     "iopub.status.busy": "2025-07-12T03:00:47.807532Z",
     "iopub.status.idle": "2025-07-12T03:00:48.829899Z",
     "shell.execute_reply": "2025-07-12T03:00:48.829203Z",
     "shell.execute_reply.started": "2025-07-12T03:00:47.807863Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Clean Text\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df[\"text\"] = df[\"text\"].fillna(\"[NO TEXT]\").apply(clean_text)\n",
    "\n",
    "# 6. Class Weights\n",
    "class_weights = compute_class_weight('balanced', classes=list(LABEL_MAP.values()), y=df_train['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# 7. Tokenizer and Transform\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038fbf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:48.831762Z",
     "iopub.status.busy": "2025-07-12T03:00:48.831039Z",
     "iopub.status.idle": "2025-07-12T03:00:48.837662Z",
     "shell.execute_reply": "2025-07-12T03:00:48.837010Z",
     "shell.execute_reply.started": "2025-07-12T03:00:48.831729Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8. Dataset\n",
    "class MemeCLIPDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, transform, is_train=True):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row.image_path).convert(\"RGB\")\n",
    "        ocr_text = row.text\n",
    "        text_encoding = self.tokenizer(ocr_text, padding=\"max_length\", truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        image_tensor = self.transform(image)\n",
    "\n",
    "        sample = {\n",
    "            \"input_ids\": text_encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": text_encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"pixel_values\": image_tensor\n",
    "        }\n",
    "\n",
    "        if self.is_train:\n",
    "            sample[\"label\"] = int(row.label)\n",
    "        else:\n",
    "            sample[\"index\"] = row[\"index\"]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2507695",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:49.915357Z",
     "iopub.status.busy": "2025-07-12T03:00:49.914813Z",
     "iopub.status.idle": "2025-07-12T03:00:49.920545Z",
     "shell.execute_reply": "2025-07-12T03:00:49.919928Z",
     "shell.execute_reply.started": "2025-07-12T03:00:49.915331Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 9. Collate Function\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n",
    "    attention_mask = torch.stack([x[\"attention_mask\"] for x in batch])\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    if \"label\" in batch[0]:\n",
    "        labels = torch.tensor([x[\"label\"] for x in batch])\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    else:\n",
    "        indices = [x[\"index\"] for x in batch]\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"pixel_values\": pixel_values, \"index\": indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b892b6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:52.315279Z",
     "iopub.status.busy": "2025-07-12T03:00:52.314767Z",
     "iopub.status.idle": "2025-07-12T03:00:52.321139Z",
     "shell.execute_reply": "2025-07-12T03:00:52.320393Z",
     "shell.execute_reply.started": "2025-07-12T03:00:52.315254Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 10. MemeCLIP Model\n",
    "class MemeCLIP(nn.Module):\n",
    "    def __init__(self, text_model, image_model, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.text_encoder = text_model\n",
    "        self.image_encoder = image_model\n",
    "        self.image_proj = nn.Linear(2048, 768)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(768*2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
    "        text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_emb = text_out.last_hidden_state[:, 0, :]\n",
    "        img_feat = self.image_encoder(pixel_values)\n",
    "        img_emb = self.image_proj(img_feat)\n",
    "        fused = torch.cat([text_emb, img_emb], dim=1)\n",
    "        logits = self.classifier(self.dropout(fused))\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss(weight=class_weights.to(logits.device))(logits, labels)\n",
    "            return loss, logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4036a166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:54.555459Z",
     "iopub.status.busy": "2025-07-12T03:00:54.554865Z",
     "iopub.status.idle": "2025-07-12T03:00:58.826445Z",
     "shell.execute_reply": "2025-07-12T03:00:58.825620Z",
     "shell.execute_reply.started": "2025-07-12T03:00:54.555435Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 11. Prepare DataLoaders\n",
    "train_dataset = MemeCLIPDataset(df_train, tokenizer, img_transform)\n",
    "val_dataset = MemeCLIPDataset(df_val, tokenizer, img_transform)\n",
    "test_dataset = MemeCLIPDataset(df_test, tokenizer, img_transform, is_train=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "# 12. Load Models and Init\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.fc = nn.Identity()\n",
    "model = MemeCLIP(bert_model, resnet_model).to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "total_steps = len(train_loader) * 10\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dfd0b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:00:58.828495Z",
     "iopub.status.busy": "2025-07-12T03:00:58.828199Z",
     "iopub.status.idle": "2025-07-12T03:00:58.836214Z",
     "shell.execute_reply": "2025-07-12T03:00:58.835586Z",
     "shell.execute_reply.started": "2025-07-12T03:00:58.828454Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 13. Train & Eval Functions\n",
    "def train_one_epoch(model, loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss, preds, labels = 0, [], []\n",
    "    for batch in tqdm(loader, desc=\"Train\"):\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "        loss, logits = model(**batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "        preds += logits.argmax(1).cpu().tolist()\n",
    "        labels += batch[\"labels\"].cpu().tolist()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return total_loss/len(loader), acc, f1\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss, preds, labels = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Eval\"):\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            loss, logits = model(**batch)\n",
    "            total_loss += loss.item()\n",
    "            preds += logits.argmax(1).cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return total_loss/len(loader), acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02674f91",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-12T03:02:30.543936Z",
     "iopub.status.busy": "2025-07-12T03:02:30.543207Z",
     "iopub.status.idle": "2025-07-12T03:51:53.834226Z",
     "shell.execute_reply": "2025-07-12T03:51:53.833461Z",
     "shell.execute_reply.started": "2025-07-12T03:02:30.543911Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 14. Training Loop with Early Stopping\n",
    "best_f1 = 0\n",
    "patience = 3\n",
    "counter = 0\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch+1}\")\n",
    "    tr_loss, tr_acc, tr_f1 = train_one_epoch(model, train_loader, optimizer, scheduler, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    val_loss, val_acc, val_f1 = evaluate(model, val_loader, torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    print(f\"Train Loss: {tr_loss:.4f} | Acc: {tr_acc:.4f} | F1: {tr_f1:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | F1: {val_f1:.4f}\")\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        print(\"✅ Saved best model\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"⏹️ Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f01845e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:52:11.280548Z",
     "iopub.status.busy": "2025-07-12T03:52:11.280058Z",
     "iopub.status.idle": "2025-07-12T03:52:11.284108Z",
     "shell.execute_reply": "2025-07-12T03:52:11.283351Z",
     "shell.execute_reply.started": "2025-07-12T03:52:11.280524Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # 15. Inference and Export to JSON\n",
    "# def predict_and_export(model, loader, output_file=\"submission.json\"):\n",
    "#     model.eval()\n",
    "#     predictions = []\n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(loader, desc=\"Predicting\"):\n",
    "#             indices = batch.pop(\"index\")\n",
    "#             batch = {k: v.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "#             logits = model(**batch)\n",
    "#             preds = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "#             for idx, label in zip(indices, preds):\n",
    "#                 predictions.append({\"index\": idx, \"prediction\": INVERSE_LABEL_MAP[label]})\n",
    "#     with open(output_file, \"w\") as f:\n",
    "#         json.dump(predictions, f, indent=2)\n",
    "#     print(f\"✅ Predictions saved to {output_file}\")\n",
    "\n",
    "# # Load Best Model and Predict\n",
    "# model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "# predict_and_export(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9055f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:52:15.541379Z",
     "iopub.status.busy": "2025-07-12T03:52:15.540659Z",
     "iopub.status.idle": "2025-07-12T03:52:15.547842Z",
     "shell.execute_reply": "2025-07-12T03:52:15.547070Z",
     "shell.execute_reply.started": "2025-07-12T03:52:15.541358Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_and_export(model, loader, output_file=\"submission.json\"):\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Predicting\"):\n",
    "            indices = batch.pop(\"index\")\n",
    "            indices = [str(i) for i in indices]  # ensure index is string like '20568.png'\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            logits = model(**batch)\n",
    "            if isinstance(logits, tuple):\n",
    "                logits = logits[1]\n",
    "            preds = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "\n",
    "            for idx, label in zip(indices, preds):\n",
    "                predictions.append({\"index\": idx, \"prediction\": label})\n",
    "    predictions = sorted(predictions, key=lambda x: x[\"index\"])\n",
    "    # Write each prediction as one JSON object per line\n",
    "    with open(output_file, \"w\") as f:\n",
    "        for item in predictions:\n",
    "            json.dump(item, f)\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "    print(f\"✅ Predictions saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a6e3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:52:24.232681Z",
     "iopub.status.busy": "2025-07-12T03:52:24.232144Z",
     "iopub.status.idle": "2025-07-12T03:52:24.733767Z",
     "shell.execute_reply": "2025-07-12T03:52:24.732988Z",
     "shell.execute_reply.started": "2025-07-12T03:52:24.232655Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load best weights\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0cf16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-12T03:52:26.972020Z",
     "iopub.status.busy": "2025-07-12T03:52:26.971733Z",
     "iopub.status.idle": "2025-07-12T03:52:55.667707Z",
     "shell.execute_reply": "2025-07-12T03:52:55.666935Z",
     "shell.execute_reply.started": "2025-07-12T03:52:26.971998Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Export predictions to file\n",
    "predict_and_export(model, test_loader, output_file=\"submission.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376fe283",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# 2. Clip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d49b61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:41:59.905618Z",
     "iopub.status.busy": "2025-07-11T12:41:59.905060Z",
     "iopub.status.idle": "2025-07-11T12:41:59.910685Z",
     "shell.execute_reply": "2025-07-11T12:41:59.909792Z",
     "shell.execute_reply.started": "2025-07-11T12:41:59.905596Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Upgraded MemeCLIP Stance Classification Model\n",
    "# =====================\n",
    "\n",
    "import os, re, json, random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision.transforms import Compose, RandomResizedCrop, RandomHorizontalFlip, ColorJitter, ToTensor, Normalize\n",
    "from transformers import CLIPProcessor, CLIPModel, get_cosine_schedule_with_warmup\n",
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4ade4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:00.321798Z",
     "iopub.status.busy": "2025-07-11T12:42:00.321406Z",
     "iopub.status.idle": "2025-07-11T12:42:00.486178Z",
     "shell.execute_reply": "2025-07-11T12:42:00.485581Z",
     "shell.execute_reply.started": "2025-07-11T12:42:00.321780Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Constants and Paths\n",
    "# =====================\n",
    "LABEL_MAP = {'Neutral': 0, 'Support': 1, 'Oppose': 2}\n",
    "INVERSE_LABEL_MAP = {v: k for k, v in LABEL_MAP.items()}\n",
    "root = \"/kaggle/input/subtask3-comp2025-multimodel/\"\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "# =====================\n",
    "# Text Cleaning\n",
    "# =====================\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|@\\w+|#\\w+|[^\\w\\s]\", \"\", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "# =====================\n",
    "# Data Loading\n",
    "# =====================\n",
    "def getIndexAndPath(folder):\n",
    "    paths = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.lower().endswith(\".png\"):\n",
    "            paths.append({\"index\": filename, \"image_path\": os.path.join(folder, filename)})\n",
    "    return paths\n",
    "\n",
    "# Load DataFrames\n",
    "# Train DF\n",
    "records = []\n",
    "for label_name in os.listdir(os.path.join(root, \"train/Subtask C Train\")):\n",
    "    label_folder = os.path.join(os.path.join(root, \"train/Subtask C Train\"), label_name)\n",
    "    if not os.path.isdir(label_folder): continue\n",
    "    label_id = LABEL_MAP[label_name]\n",
    "    records += getIndexAndPath(label_folder)\n",
    "df_images = pd.DataFrame(records)\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"train/STask_C_train.csv\"))\n",
    "df_train = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "# Test DF\n",
    "df_images = pd.DataFrame(getIndexAndPath(os.path.join(root, \"test/STask_C_test_img\")))\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"test/STask-C(index,text)test.csv\"))\n",
    "df_test = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "# Eval DF\n",
    "df_images = pd.DataFrame(getIndexAndPath(os.path.join(root, \"eval/STask_C_val_img\")))\n",
    "df_ocr = pd.read_csv(os.path.join(root, \"eval/STask-C(index,text)val.csv\"))\n",
    "df_labels = pd.read_csv(os.path.join(root, \"eval/STask-C(index,label)val.csv\"))\n",
    "df_eval = pd.merge(df_images, df_ocr, on=\"index\", how=\"left\")\n",
    "df_val = pd.merge(df_eval, df_labels, on=\"index\", how=\"left\")\n",
    "# Clean text\n",
    "for df in [df_train, df_val, df_test]:\n",
    "    df[\"text\"] = df[\"text\"].fillna(\"[NO TEXT]\").apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ac55f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:00.504735Z",
     "iopub.status.busy": "2025-07-11T12:42:00.504564Z",
     "iopub.status.idle": "2025-07-11T12:42:00.513924Z",
     "shell.execute_reply": "2025-07-11T12:42:00.513263Z",
     "shell.execute_reply.started": "2025-07-11T12:42:00.504721Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64762c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:00.709086Z",
     "iopub.status.busy": "2025-07-11T12:42:00.708890Z",
     "iopub.status.idle": "2025-07-11T12:42:02.366417Z",
     "shell.execute_reply": "2025-07-11T12:42:02.365771Z",
     "shell.execute_reply.started": "2025-07-11T12:42:00.709071Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Compute Class Weights\n",
    "# =====================\n",
    "class_weights = compute_class_weight('balanced', classes=list(LABEL_MAP.values()), y=df_train['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "# =====================\n",
    "# Transforms and Processor\n",
    "# =====================\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc706931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:02.367809Z",
     "iopub.status.busy": "2025-07-11T12:42:02.367572Z",
     "iopub.status.idle": "2025-07-11T12:42:02.372932Z",
     "shell.execute_reply": "2025-07-11T12:42:02.372170Z",
     "shell.execute_reply.started": "2025-07-11T12:42:02.367785Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Transforms\n",
    "# =====================\n",
    "train_transform = Compose([\n",
    "    RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    RandomHorizontalFlip(),\n",
    "    ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "    ToTensor(),\n",
    "    Normalize([0.48145466, 0.4578275, 0.40821073], [0.26862954, 0.26130258, 0.27577711])\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize([0.48145466, 0.4578275, 0.40821073], [0.26862954, 0.26130258, 0.27577711])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bd1ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:05.592525Z",
     "iopub.status.busy": "2025-07-11T12:42:05.592230Z",
     "iopub.status.idle": "2025-07-11T12:42:05.600516Z",
     "shell.execute_reply": "2025-07-11T12:42:05.599778Z",
     "shell.execute_reply.started": "2025-07-11T12:42:05.592503Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Dataset and Collate\n",
    "# =====================\n",
    "class MemeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, is_train=True):\n",
    "        self.df = df\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row.image_path).convert(\"RGB\")\n",
    "        if self.transform: image = self.transform(image)\n",
    "        text = row.text\n",
    "        sample = clip_processor(\n",
    "            text=[text], images=image,\n",
    "            return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=128\n",
    "        )\n",
    "        sample = {k: v.squeeze(0) for k, v in sample.items()}\n",
    "        if self.is_train:\n",
    "            sample[\"label\"] = int(row.label)\n",
    "        else:\n",
    "            sample[\"index\"] = row[\"index\"]\n",
    "        return sample\n",
    "\n",
    "def collate_fn(batch):\n",
    "    input_ids = torch.stack([x[\"input_ids\"] for x in batch])\n",
    "    attention_mask = torch.stack([x[\"attention_mask\"] for x in batch])\n",
    "    pixel_values = torch.stack([x[\"pixel_values\"] for x in batch])\n",
    "    if \"label\" in batch[0]:\n",
    "        labels = torch.tensor([x[\"label\"] for x in batch])\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"pixel_values\": pixel_values, \"labels\": labels}\n",
    "    else:\n",
    "        indices = [x[\"index\"] for x in batch]\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"pixel_values\": pixel_values, \"index\": indices}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff8501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:07.697461Z",
     "iopub.status.busy": "2025-07-11T12:42:07.697176Z",
     "iopub.status.idle": "2025-07-11T12:42:07.702565Z",
     "shell.execute_reply": "2025-07-11T12:42:07.701830Z",
     "shell.execute_reply.started": "2025-07-11T12:42:07.697420Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Focal Loss\n",
    "# =====================\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, weight=None):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss(weight=weight)\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        return ((1 - p) ** self.gamma * logp).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4921e334",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:09.773488Z",
     "iopub.status.busy": "2025-07-11T12:42:09.773232Z",
     "iopub.status.idle": "2025-07-11T12:42:09.779306Z",
     "shell.execute_reply": "2025-07-11T12:42:09.778616Z",
     "shell.execute_reply.started": "2025-07-11T12:42:09.773471Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Model Wrapper\n",
    "# =====================\n",
    "class CLIPClassifier(nn.Module):\n",
    "    def __init__(self, clip_model, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.clip = clip_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        self.loss_fn = FocalLoss(weight=class_weights.to(device))\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values, labels=None):\n",
    "        outputs = self.clip(input_ids=input_ids, attention_mask=attention_mask, pixel_values=pixel_values)\n",
    "        text_emb = outputs.text_embeds\n",
    "        image_emb = outputs.image_embeds\n",
    "        fused = torch.cat([text_emb, image_emb], dim=1)\n",
    "        logits = self.classifier(fused)\n",
    "        if labels is not None:\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return loss, logits\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06ba0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:11.709701Z",
     "iopub.status.busy": "2025-07-11T12:42:11.709428Z",
     "iopub.status.idle": "2025-07-11T12:42:11.960668Z",
     "shell.execute_reply": "2025-07-11T12:42:11.959992Z",
     "shell.execute_reply.started": "2025-07-11T12:42:11.709681Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Load Data\n",
    "# =====================\n",
    "val_dataset = MemeDataset(df_val, transform=val_transform)\n",
    "test_dataset = MemeDataset(df_test, transform=val_transform, is_train=False)\n",
    "\n",
    "# Weighted Sampling\n",
    "class_counts = df_train['label'].value_counts().sort_index().values\n",
    "sampling_weights = 1. / class_counts\n",
    "sample_weights = df_train['label'].apply(lambda x: sampling_weights[x])\n",
    "sampler = WeightedRandomSampler(sample_weights.tolist(), len(sample_weights), replacement=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "model = CLIPClassifier(clip_model).to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "total_steps = len(train_loader) * 10\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, int(0.1 * total_steps), total_steps)\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bbb051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:13.668276Z",
     "iopub.status.busy": "2025-07-11T12:42:13.667702Z",
     "iopub.status.idle": "2025-07-11T12:42:13.676712Z",
     "shell.execute_reply": "2025-07-11T12:42:13.675910Z",
     "shell.execute_reply.started": "2025-07-11T12:42:13.668254Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Training and Eval\n",
    "# =====================\n",
    "def train_one_epoch(model, loader):\n",
    "    model.train()\n",
    "    total_loss, preds, labels = 0, [], []\n",
    "    for batch in tqdm(loader, desc=\"Training\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss, logits = model(**batch)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        total_loss += loss.item()\n",
    "        preds += logits.argmax(1).detach().cpu().tolist()\n",
    "        labels += batch[\"labels\"].cpu().tolist()\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return total_loss / len(loader), acc, f1\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, preds, labels = 0, [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            loss, logits = model(**batch)\n",
    "            total_loss += loss.item()\n",
    "            preds += logits.argmax(1).cpu().tolist()\n",
    "            labels += batch[\"labels\"].cpu().tolist()\n",
    "    print(classification_report(labels, preds, target_names=LABEL_MAP.keys()))\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"macro\")\n",
    "    return total_loss / len(loader), acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c1c022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-11T12:42:16.398110Z",
     "iopub.status.busy": "2025-07-11T12:42:16.397451Z",
     "iopub.status.idle": "2025-07-11T12:42:16.832567Z",
     "shell.execute_reply": "2025-07-11T12:42:16.831410Z",
     "shell.execute_reply.started": "2025-07-11T12:42:16.398086Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Training Loop\n",
    "# =====================\n",
    "best_f1 = 0\n",
    "patience = 3\n",
    "counter = 0\n",
    "for epoch in range(10):\n",
    "    print(f\"\\nEpoch {epoch + 1}\")\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader)\n",
    "    val_loss, val_acc, val_f1 = evaluate(model, val_loader)\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f}, F1: {train_f1:.4f}\")\n",
    "    print(f\"Val   Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), \"best_clip_model.pt\")\n",
    "        print(\"✅ Saved best model\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"⏹️ Early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e10da1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Inference\n",
    "# =====================\n",
    "def predict_and_export(model, loader, output_file=\"submission.json\"):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Predicting\"):\n",
    "            indices = batch.pop(\"index\")\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            logits = model(**batch)\n",
    "            if isinstance(logits, tuple): logits = logits[1]\n",
    "            preds = torch.argmax(logits, dim=1).cpu().tolist()\n",
    "            for idx, label in zip(indices, preds):\n",
    "                predictions.append({\"index\": idx, \"prediction\": INVERSE_LABEL_MAP[label]})\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(predictions, f, indent=2)\n",
    "    print(f\"✅ Predictions saved to {output_file}\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_clip_model.pt\"))\n",
    "predict_and_export(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7841536,
     "sourceId": 12431539,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.138508,
   "end_time": "2025-07-12T03:58:07.895387",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-12T03:57:23.756879",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
